{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMumxkTxfnX4",
        "outputId": "54173118-0090-45e0-85ad-9abc44b5696d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "0DaTtqBSfqYy",
        "outputId": "adde22f2-bf1b-459b-aff1-3046dd2d58f3"
      },
      "outputs": [],
      "source": [
        "# Load the full dataset (this reads ~200K articles)\n",
        "df = pd.read_parquet('https://storage.googleapis.com/msca-bdp-data-open/news_final_project/news_final_project.parquet', engine='pyarrow')\n",
        "\n",
        "# Preview the shape and the first few rows\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZUN0_XWfrx0",
        "outputId": "5e033af7-c739-4fdd-fa62-145ddd5af475"
      },
      "outputs": [],
      "source": [
        "# Basic info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "6gi3ZTzMft3L",
        "outputId": "15a86af3-6354-403b-c352-b425c62c8c90"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oPQaUgLdfvbq",
        "outputId": "b5ddc66d-6ce1-412c-e0d0-2e07ac3c095b"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "Ep_XpcXWfw7x",
        "outputId": "81eff369-6caf-4dc0-fe23-59226706f05a"
      },
      "outputs": [],
      "source": [
        "# Check the range of article dates\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "print(\"Date Range:\", df['date'].min(), \"to\", df['date'].max())\n",
        "\n",
        "# Article length (number of characters in text)\n",
        "df['text_length'] = df['text'].astype(str).apply(len)\n",
        "df['text_length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "RW6CzFxOfy5l",
        "outputId": "f13ce1b7-761f-4975-c37d-0efd2b54e061"
      },
      "outputs": [],
      "source": [
        "# Check language distribution\n",
        "df['language'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s103oDiYf0cw",
        "outputId": "43e4129b-1a71-490a-b3b4-1b1b2cc592ff"
      },
      "outputs": [],
      "source": [
        "# Find empty or very short articles\n",
        "df[df['text_length'] < 50][['title', 'text', 'text_length']].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "1bIWRy4wf2Yv",
        "outputId": "addedcdc-f99d-4c8b-8467-4332383754ff"
      },
      "outputs": [],
      "source": [
        "# Plot Article Count Over Time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group by month and count\n",
        "df['year_month'] = df['date'].dt.to_period('M')\n",
        "article_counts = df.groupby('year_month').size()\n",
        "\n",
        "# Plot\n",
        "article_counts.plot(kind='line', figsize=(12, 6), title='Article Count Over Time')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.xlabel('Year-Month')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lydXupf6WG"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWLprG8Wf32_"
      },
      "outputs": [],
      "source": [
        "# Convert date column to datetime\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcNNf7wrf84o"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates\n",
        "df = df.drop_duplicates(subset=['title', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sanxUkpcf-iU"
      },
      "outputs": [],
      "source": [
        "# Remove short articles (less than 50 characters)\n",
        "df['text_length'] = df['text'].astype(str).apply(len)\n",
        "df = df[df['text_length'] >= 50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ejGoXU3ef_53",
        "outputId": "e821473f-2a4f-4f68-b8f5-98a051caec4d"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    # Remove repeated whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove emails\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    # Remove special characters & digits (except basic punctuation)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?'\\s]\", '', text)\n",
        "    # Normalize whitespace again\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WstjKruagDLe"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'].swifter.apply(clean_text)\n",
        "df['title'] = df['title'].swifter.apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceLPJ3EFgEuc"
      },
      "outputs": [],
      "source": [
        "# Reset index\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2z7EZd1gGD3"
      },
      "outputs": [],
      "source": [
        "# Drop helper column\n",
        "df.drop(columns=['text_length'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA5TOQGSgHTi"
      },
      "outputs": [],
      "source": [
        "# Show cleaned shape and preview\n",
        "print(\"Cleaned dataset shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n6PjsG5gLTR"
      },
      "source": [
        "### Topic Modeling with BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifu1Sp7NgJNs"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj8B251ggNBJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.backends.mps.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tAg6Go5gOtP"
      },
      "outputs": [],
      "source": [
        "# Load transformer model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "# Create BERTopic model using the custom embedding model\n",
        "topic_model = BERTopic(embedding_model=embedding_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNaLPO-mgQM0"
      },
      "outputs": [],
      "source": [
        "# Extract documents\n",
        "docs = df['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVrXpaZEgTdr"
      },
      "outputs": [],
      "source": [
        "topics, probs = topic_model.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERX_8UYZgVJO"
      },
      "outputs": [],
      "source": [
        "# Add topic column to df\n",
        "df['topic'] = topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxbtqEeNgVf4"
      },
      "outputs": [],
      "source": [
        "industry_keywords = {\n",
        "    \"Finance\": [\n",
        "        \"stock\", \"market\", \"investment\", \"nasdaq\", \"bank\", \"currency\", \"crypto\", \"equity\", \"fintech\", \"trading\",\n",
        "        \"shares\", \"bonds\", \"interest rate\", \"asset\", \"portfolio\", \"hedge fund\", \"exchange\", \"decentralized finance\",\n",
        "        \"payment\", \"financial services\", \"robo-advisor\", \"wealth management\", \"finra\", \"securities\", \"credit\",\n",
        "        \"valuation\", \"ipo\", \"debt\", \"derivatives\", \"risk management\"],\n",
        "    \"Healthcare\": [\n",
        "        \"patient\", \"hospital\", \"diagnosis\", \"therapy\", \"healthcare\", \"clinical\", \"treatment\", \"medical\", \"doctor\",\n",
        "        \"nurse\", \"biotech\", \"covid\", \"vaccine\", \"fda\", \"pharma\", \"drug\", \"genomics\", \"public health\", \"telemedicine\",\n",
        "        \"health tech\", \"clinical trial\", \"health data\", \"ehr\", \"radiology\", \"diagnostic\", \"health insurance\",\n",
        "        \"mental health\", \"imaging\", \"medtech\", \"robotic surgery\", \"cancer\", \"prescription\", \"surgeon\",\n",
        "        \"hospitalization\", \"outpatient\"],\n",
        "    \"Education\": [\n",
        "        \"student\", \"school\", \"university\", \"curriculum\", \"learning\", \"teaching\", \"classroom\", \"online course\",\n",
        "        \"edtech\", \"professor\", \"exam\", \"degree\", \"certificate\", \"elearning\", \"tutorial\", \"lecture\", \"academic\",\n",
        "        \"homework\", \"syllabus\", \"tutor\", \"k-12\", \"mooc\", \"higher education\", \"remote learning\", \"grade\",\n",
        "        \"assignment\", \"lms\", \"grading\", \"student success\", \"exam proctoring\", \"enrollment\", \"scholarship\",\n",
        "        \"textbook\", \"instructional design\"],\n",
        "    \"Media / News\": [\n",
        "        \"press\", \"newswire\", \"reporter\", \"headline\", \"journalist\", \"publication\", \"article\", \"newsletter\", \"media\",\n",
        "        \"cnn\", \"bbc\", \"reuters\", \"bloomberg\", \"nytimes\", \"forbes\", \"guardian\", \"washington post\", \"news release\",\n",
        "        \"media outlet\", \"broadcast\", \"coverage\", \"opinion\", \"editorial\", \"newsroom\", \"column\", \"interview\", \"breaking news\",\n",
        "        \"media strategy\", \"fact checking\", \"news curation\", \"media bias\", \"breaking coverage\", \"subscription model\",\n",
        "        \"content syndication\", \"media partnership\"],\n",
        "    \"Retail / Consumer\": [\n",
        "        \"ecommerce\", \"retail\", \"shopping\", \"consumer\", \"brand\", \"product\", \"shop\", \"cart\", \"checkout\", \"amazon\",\n",
        "        \"fashion\", \"warehouse\", \"store\", \"grocery\", \"inventory\", \"supply chain\", \"logistics\", \"promotion\", \"sale\",\n",
        "        \"payment\", \"delivery\", \"online store\", \"customer\", \"review\", \"discount\", \"return policy\", \"order\", \"receipt\",\n",
        "        \"point of sale\", \"digital shelf\", \"retail analytics\", \"coupon\", \"in-store\", \"loyalty program\", \"merchandise\"],\n",
        "    \"Transportation\": [\n",
        "        \"vehicle\", \"car\", \"fleet\", \"autonomous\", \"driver\", \"road\", \"traffic\", \"logistics\", \"delivery\", \"rideshare\",\n",
        "        \"rail\", \"bus\", \"highway\", \"driving\", \"mobility\", \"EV\", \"charging station\", \"tire\", \"fuel\", \"infrastructure\",\n",
        "        \"navigation\", \"transport\", \"transit\", \"freight\", \"commute\"],\n",
        "    \"Legal / Regulatory\": [\n",
        "        \"law\", \"court\", \"regulation\", \"rights\", \"compliance\", \"privacy\", \"lawsuit\", \"litigation\", \"policy\",\n",
        "        \"jurisdiction\", \"ethics\", \"intellectual property\", \"terms\", \"legal framework\", \"gdpr\", \"contract\",\n",
        "        \"attorney\", \"subpoena\", \"data protection\", \"anti-trust\", \"legal challenge\", \"enforcement\"],\n",
        "    \"Agriculture\": [\n",
        "        \"farming\", \"crop\", \"soil\", \"harvest\", \"livestock\", \"irrigation\", \"pesticide\", \"fertilizer\", \"drought\",\n",
        "        \"tractor\", \"yield\", \"planting\", \"agriculture\", \"greenhouse\", \"weather\", \"agribusiness\", \"seed\",\n",
        "        \"barn\", \"farmer\", \"organic\", \"sustainability\", \"rural\", \"cultivation\", \"field\"],\n",
        "    \"Real Estate / Housing\": [\n",
        "        \"property\", \"rent\", \"mortgage\", \"house\", \"apartment\", \"zillow\", \"landlord\", \"realtor\", \"tenant\",\n",
        "        \"residential\", \"housing\", \"lease\", \"broker\", \"condo\", \"foreclosure\", \"neighborhood\", \"zoning\",\n",
        "        \"renovation\", \"realty\", \"mortgage rate\", \"listing\", \"property tax\", \"homeowner\"],\n",
        "    \"Travel / Tourism\": [\n",
        "        \"hotel\", \"flight\", \"vacation\", \"airline\", \"airport\", \"travel\", \"tourism\", \"destination\", \"booking\",\n",
        "        \"resort\", \"itinerary\", \"passport\", \"trip\", \"luggage\", \"cruise\", \"visa\", \"guidebook\", \"tour\",\n",
        "        \"excursion\", \"hospitality\", \"accommodation\", \"check-in\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmP3236VgYop"
      },
      "outputs": [],
      "source": [
        "# Label topics using keyword matching\n",
        "def label_topic(keywords):\n",
        "    for industry, kw_list in industry_keywords.items():\n",
        "        if any(kw.lower() in keywords for kw in kw_list):\n",
        "            return industry\n",
        "    return \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyduSYp5gaUN"
      },
      "outputs": [],
      "source": [
        "# Extract keywords from BERTopic and apply labels\n",
        "topics_keywords = topic_model.get_topics()\n",
        "topic_to_label = {}\n",
        "for topic_id, word_list in topics_keywords.items():\n",
        "    top_keywords = [kw.lower() for kw, _ in word_list[:10]]\n",
        "    topic_to_label[topic_id] = label_topic(top_keywords)\n",
        "\n",
        "df['topic_label'] = df['topic'].map(topic_to_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD0TzWzUgboE"
      },
      "outputs": [],
      "source": [
        "# set category order for plotting\n",
        "df['topic_label'] = pd.Categorical(\n",
        "    df['topic_label'],\n",
        "    categories=list(industry_keywords.keys()),\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "df[['title', 'topic', 'topic_label']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6Yac9hDgdLT"
      },
      "outputs": [],
      "source": [
        "df[df['topic_label'].notnull()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qo7r_J2geY5"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVd2WSxegfyN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Count and sort\n",
        "topic_counts = df['topic_label'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=topic_counts.values, y=topic_counts.index, palette=\"tab10\")\n",
        "plt.title(\"Article Count by Topic Label\")\n",
        "plt.xlabel(\"Number of Articles\")\n",
        "plt.ylabel(\"Topic Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeI2ZhgDghdP"
      },
      "outputs": [],
      "source": [
        "# Ensure 'date' is datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year_month'] = df['date'].dt.to_period('M').astype(str)\n",
        "\n",
        "# Group by time + topic label\n",
        "topic_timeline = df.groupby(['year_month', 'topic_label']).size().reset_index(name='count')\n",
        "timeline_pivot = topic_timeline.pivot(index='year_month', columns='topic_label', values='count').fillna(0)\n",
        "\n",
        "# Plot\n",
        "timeline_pivot.plot(figsize=(14, 6), marker='o')\n",
        "plt.title(\"Articles Over Time by Topic Label\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Topic Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K5Oa428glFS"
      },
      "source": [
        "### Topic Modeling with LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zwEcwmcg5IG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.matutils import Sparse2Corpus\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUAjerc1gjGd"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elAd6VnWg6uN"
      },
      "outputs": [],
      "source": [
        "texts = df['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv5OmWZlg8Yb"
      },
      "outputs": [],
      "source": [
        "# Basic text preprocessing\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # Keep only letters\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stop_words and len(word) > 3]\n",
        "    return text\n",
        "\n",
        "# Clean all texts\n",
        "processed_texts = [clean_text(doc) for doc in tqdm(texts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBHUgcZcg9wf"
      },
      "outputs": [],
      "source": [
        "# Create dictionary and corpus\n",
        "dictionary = corpora.Dictionary(processed_texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0iRIMcqg_a-"
      },
      "outputs": [],
      "source": [
        "# Train LDA model\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=10,  # Set number of topics\n",
        "    passes=10,\n",
        "    random_state=42,\n",
        "    per_word_topics=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Yl6SmThA5v"
      },
      "outputs": [],
      "source": [
        "# Print top words for each topic\n",
        "for idx, topic in lda_model.print_topics(num_topics=10, num_words=10):\n",
        "    print(f\"Topic {idx}:\\n{topic}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSQGjhnShCRQ"
      },
      "outputs": [],
      "source": [
        "# Assign dominant topic to each document\n",
        "def get_dominant_topic(bow):\n",
        "    topic_probs = lda_model.get_document_topics(bow)\n",
        "    if topic_probs:\n",
        "        return max(topic_probs, key=lambda x: x[1])[0]\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "df['lda_topic'] = [get_dominant_topic(bow) for bow in corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APkEKr-ehEVS"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary mapping topic number to industry\n",
        "topic_industry_mapping = {\n",
        "    0: \"Generative AI & Tech News\",\n",
        "    1: \"Healthcare & Medical Imaging\",\n",
        "    2: \"Market Research & Regional Industry News\",\n",
        "    3: \"AI, Data Science & Cybersecurity\",\n",
        "    4: \"Indian Business & Tech Updates\",\n",
        "    5: \"Media Releases & Tech Platforms\",\n",
        "    6: \"Local News & Weather Reports\",\n",
        "    7: \"Financial Markets & Services\",\n",
        "    8: \"Entertainment & Celebrity News\",\n",
        "    9: \"Consumer Tech & Product Reviews\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzjJM9TDhGV7"
      },
      "outputs": [],
      "source": [
        "# Map topic to industry\n",
        "df['lda_industry'] = df['lda_topic'].map(topic_industry_mapping)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiZiHHg9hHie"
      },
      "outputs": [],
      "source": [
        "# Prepare BERTopic distribution\n",
        "bertopic_counts = df['topic_label'].value_counts().sort_values(ascending=True)\n",
        "\n",
        "# Prepare LDA distribution\n",
        "lda_counts = df['lda_industry'].value_counts().sort_index()  # 0 to 9\n",
        "lda_counts.index = [i for i in lda_counts.index]\n",
        "\n",
        "# Plot side-by-side\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# BERTopic plot\n",
        "sns.barplot(x=bertopic_counts.values, y=bertopic_counts.index, ax=axs[0], palette=\"tab10\")\n",
        "axs[0].set_title(\"BERTopic: Articles per Topic Label\")\n",
        "axs[0].set_xlabel(\"Number of Articles\")\n",
        "axs[0].set_ylabel(\"Topic Label\")\n",
        "\n",
        "# LDA plot\n",
        "sns.barplot(x=lda_counts.values, y=lda_counts.index, ax=axs[1], palette=\"tab10\")\n",
        "axs[1].set_title(\"LDA: Articles per Topic\")\n",
        "axs[1].set_xlabel(\"Number of Articles\")\n",
        "axs[1].set_ylabel(\"Topic ID\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYu05PClhJX-"
      },
      "outputs": [],
      "source": [
        "# Ensure datetime column exists\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year_month'] = df['date'].dt.to_period('M').astype(str)\n",
        "\n",
        "# Group by BERTopic topic label\n",
        "bertopic_time = df.groupby(['year_month', 'topic_label']).size().reset_index(name='count')\n",
        "ber_pivot = bertopic_time.pivot(index='year_month', columns='topic_label', values='count').fillna(0)\n",
        "\n",
        "# Group by LDA topic\n",
        "lda_time = df.groupby(['year_month', 'lda_industry']).size().reset_index(name='count')\n",
        "lda_time['lda_industry'] = lda_time['lda_industry'].apply(lambda x: f\"{x}\")\n",
        "lda_pivot = lda_time.pivot(index='year_month', columns='lda_industry', values='count').fillna(0)\n",
        "\n",
        "# Plot\n",
        "fig, axs = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "ber_pivot.plot(ax=axs[0], marker='o')\n",
        "axs[0].set_title(\"BERTopic: Article Volume Over Time\")\n",
        "axs[0].set_ylabel(\"Count\")\n",
        "axs[0].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "lda_pivot.plot(ax=axs[1], marker='o')\n",
        "axs[1].set_title(\"LDA: Article Volume Over Time\")\n",
        "axs[1].set_ylabel(\"Count\")\n",
        "axs[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxjzXgLhSRN"
      },
      "source": [
        "### Another Method with BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06uXPBldhMi2"
      },
      "outputs": [],
      "source": [
        "topic_info = topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N9UOCKchUDj"
      },
      "outputs": [],
      "source": [
        "topic_info['Representation'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2JGx8dFhVNg"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print(f\"\\nTopic {i} keywords:\")\n",
        "    print(topic_model.get_topic(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58mgJjiChWoI"
      },
      "outputs": [],
      "source": [
        "df= df[df['topic'] != -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlUiULoDhZPl"
      },
      "outputs": [],
      "source": [
        "# Get the top 10 topic IDs by count\n",
        "top_10_topics = df['topic'].value_counts().head(10).index.tolist()\n",
        "print(\"Top 10 topic IDs:\", top_10_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUAr7zYIhZ6B"
      },
      "outputs": [],
      "source": [
        "topic_to_industry = {\n",
        "    0: \"Transportation / Tech News\",\n",
        "    1: \"Media / News\",\n",
        "    2: \"AI Hardware\",\n",
        "    3: \"Finance\",\n",
        "    4: \"Education\",\n",
        "    5: \"Media / Community Tools\",\n",
        "    6: \"Cybersecurity\",\n",
        "    7: \"Tech Platforms\",\n",
        "    8: \"Finance\",\n",
        "    9: \"Tech Platforms\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE3DhEMmhbeB"
      },
      "outputs": [],
      "source": [
        "# Only keep rows with one of the top 10 topics\n",
        "df_top10 = df[df['topic'].isin(top_10_topics)].copy()\n",
        "\n",
        "# Map topic to industry\n",
        "df_top10['top_industry'] = df_top10['topic'].map(topic_to_industry)\n",
        "\n",
        "# Preview\n",
        "df_top10.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeR0GhDMhc2E"
      },
      "outputs": [],
      "source": [
        "# Count and sort industries descending\n",
        "industry_counts = df_top10['top_industry'].value_counts().sort_values(ascending=True)\n",
        "\n",
        "# Horizontal bar plot (largest on top)\n",
        "industry_counts.plot(kind='barh', title='Top Industries by Article Count', figsize=(10,6))\n",
        "plt.xlabel('Number of Articles')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMdgO2OFhej8"
      },
      "outputs": [],
      "source": [
        "# Group by time + topic label\n",
        "topic_timeline = df_top10.groupby(['year_month', 'top_industry']).size().reset_index(name='count')\n",
        "timeline_pivot = topic_timeline.pivot(index='year_month', columns='top_industry', values='count').fillna(0)\n",
        "\n",
        "# Plot\n",
        "timeline_pivot.plot(figsize=(14, 6), marker='o')\n",
        "plt.title(\"BERTopic: Articles Over Time by Topic 10 Label\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Topic 10 Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znLvN4b2hg9D"
      },
      "outputs": [],
      "source": [
        "df_top10.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bNwoFhahkXE"
      },
      "source": [
        "### NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHWbRMF8higG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujDGoZ8ihmPo"
      },
      "outputs": [],
      "source": [
        "# Step 1: TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKj8zCZ5hoNq"
      },
      "outputs": [],
      "source": [
        "# Step 2: Apply NMF\n",
        "nmf_model = NMF(n_components=10, random_state=42)\n",
        "W = nmf_model.fit_transform(tfidf)\n",
        "H = nmf_model.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWf-EfQUhpdn"
      },
      "outputs": [],
      "source": [
        "# Step 3: Display top words per topic\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_keywords = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
        "    print(f\"Topic {topic_idx}: {', '.join(top_keywords)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHouUqYThqo1"
      },
      "outputs": [],
      "source": [
        "NMF_topics = {\n",
        "    0: \"Media / News (with AI flavor)\",\n",
        "    1: \"Noise / Irrelevant (Image Metadata)\",\n",
        "    2: \"Retail / Consumer & Transportation\",\n",
        "    3: \"Finance\",\n",
        "    4: \"Media / News Distribution\",\n",
        "    5: \"Tech Platforms & Enterprise AI\",\n",
        "    6: \"News & Utility Info\",\n",
        "    7: \"Finance (Market Research & International Indices)\",\n",
        "    8: \"Finance (Indian Market Emphasis)\",\n",
        "    9: \"Tech Platforms & Consumer Devices\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lYNqJ9ThsYW"
      },
      "source": [
        "### Entity Extraction (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHMOapJ5htmg"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOq3A614hvAB"
      },
      "outputs": [],
      "source": [
        "# Load spaCy's English model\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jDAQtfIhwPs"
      },
      "outputs": [],
      "source": [
        "df_final=df[df['topic_label'].notnull()]\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0xmqwwHhxwV"
      },
      "outputs": [],
      "source": [
        "# Function to extract named entities\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    orgs = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
        "    people = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]]\n",
        "    return pd.Series([orgs, people, locations])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJxUWW3QhzLf"
      },
      "outputs": [],
      "source": [
        "# Enable progress bar\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqWVCfmOh0rU"
      },
      "outputs": [],
      "source": [
        "# Apply to the full article text\n",
        "df_final[['organizations', 'people', 'locations']] = df_final['text'].progress_apply(extract_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn4WmUwoh2QW"
      },
      "outputs": [],
      "source": [
        "df_final[['title', 'organizations', 'people', 'locations']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm9f1Xokh6Cj"
      },
      "source": [
        "#### Organazations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFxWYbKBh3on"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def normalize_org(name):\n",
        "    if name in ['Open AI', 'OpenAI']:\n",
        "        return 'OpenAI'\n",
        "    elif name in ['Meta Platforms', 'Meta']:\n",
        "        return 'Meta'\n",
        "    elif name in ['Amazon.com', 'Amazon']:\n",
        "        return 'Amazon'\n",
        "    elif name in ['Microsoft Corporation', 'Microsoft']:\n",
        "        return 'Microsoft'\n",
        "    elif name in ['Nvidia', 'NVIDIA']:\n",
        "        return 'Nvidia'\n",
        "    elif name in ['GPT', 'ChatGPT']:\n",
        "        return 'ChatGPT'\n",
        "    return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwxmd_pdiA-0"
      },
      "outputs": [],
      "source": [
        "# Convert to month\n",
        "df_final['year_month'] = pd.to_datetime(df_final['date']).dt.to_period('M').astype(str)\n",
        "\n",
        "# Store counts per (month, org)\n",
        "records = []\n",
        "\n",
        "for idx, row in tqdm(df_final.iterrows(), total=len(df_final)):\n",
        "    month = row['year_month']\n",
        "    orgs = row['organizations']\n",
        "    if isinstance(orgs, list):\n",
        "        for org in orgs:\n",
        "            org_norm = normalize_org(org)\n",
        "            records.append((month, org_norm))\n",
        "\n",
        "# Create DataFrame from counts\n",
        "df_org_mentions = pd.DataFrame(records, columns=['month', 'organization'])\n",
        "\n",
        "# Remove \"AI\" mentions from time records\n",
        "df_org_mentions = df_org_mentions[df_org_mentions['organization'] != 'AI']\n",
        "\n",
        "# Top 10 orgs overall\n",
        "top_orgs = df_org_mentions['organization'].value_counts().head(10).index.tolist()\n",
        "\n",
        "# Filter to top orgs\n",
        "df_top_orgs = df_org_mentions[df_org_mentions['organization'].isin(top_orgs)]\n",
        "\n",
        "# Group and pivot\n",
        "org_trend = (\n",
        "    df_top_orgs.groupby(['month', 'organization'])\n",
        "    .size()\n",
        "    .reset_index(name='count')\n",
        "    .pivot(index='month', columns='organization', values='count')\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iboDtJlwiETU"
      },
      "outputs": [],
      "source": [
        "# Flatten and normalize organization mentions\n",
        "all_orgs = [normalize_org(org) for sublist in df_final['organizations'] if isinstance(sublist, list) for org in sublist]\n",
        "\n",
        "# Remove \"AI\" from the list before counting\n",
        "filtered_orgs = [org for org in all_orgs if org != 'AI']\n",
        "\n",
        "# Count top 10 without \"AI\"\n",
        "top_org_counts = Counter(filtered_orgs).most_common(10)\n",
        "org_names, org_counts = zip(*top_org_counts)\n",
        "\n",
        "# Plot again\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(org_names[::-1], org_counts[::-1], color='steelblue')\n",
        "plt.xlabel(\"Mention Count\")\n",
        "plt.title(\"Top 10 Organizations in AI News (Excluding 'AI')\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuWc18B3iFx3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "org_trend.plot(marker='o', figsize=(16, 6))\n",
        "plt.title(\"Top 10 Organizations Mentioned Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Mentions\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Organization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAdeck1DiMcM"
      },
      "source": [
        "#### people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQOisNIiiHcn"
      },
      "outputs": [],
      "source": [
        "# Normalization function\n",
        "def normalize_person(name):\n",
        "    name = name.strip()\n",
        "    name_lower = name.lower()\n",
        "\n",
        "    if 'altman' in name_lower:\n",
        "        return 'Sam Altman'\n",
        "    elif 'musk' in name_lower:\n",
        "        return 'Elon Musk'\n",
        "    elif name_lower in ['biden']:\n",
        "        return 'Joe Biden'\n",
        "    elif 'trump' in name_lower:\n",
        "        return 'Donald Trump'\n",
        "    elif 'mackintosh' in name_lower:\n",
        "        return 'Phil Mackintosh'\n",
        "    elif name_lower == 'claude':\n",
        "        return 'Claude (Anthropic)'\n",
        "    elif 'huang' in name_lower:\n",
        "        return 'Jensen Huang'\n",
        "    else:\n",
        "        return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHhrp1x1iP3N"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Flatten and normalize people\n",
        "all_people = [\n",
        "    normalize_person(p)\n",
        "    for sublist in df_final['people'] if isinstance(sublist, list)\n",
        "    for p in sublist\n",
        "]\n",
        "\n",
        "# Get top 10 people\n",
        "top_people_counts = Counter(all_people).most_common(10)\n",
        "people_names, people_counts = zip(*top_people_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB1g23EIiRYF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(people_names[::-1], people_counts[::-1], color='salmon')\n",
        "plt.xlabel(\"Mention Count\")\n",
        "plt.title(\"Top 10 People in AI News\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPA5wx_siSwn"
      },
      "outputs": [],
      "source": [
        "# Add normalized mentions to timeline records\n",
        "df_final['year_month'] = pd.to_datetime(df_final['date']).dt.to_period('M').astype(str)\n",
        "\n",
        "records = []\n",
        "for i, row in df_final.iterrows():\n",
        "    if isinstance(row['people'], list):\n",
        "        for p in row['people']:\n",
        "            person = normalize_person(p)\n",
        "            records.append((row['year_month'], person))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_people_mentions = pd.DataFrame(records, columns=['month', 'person'])\n",
        "\n",
        "# Filter to top 10\n",
        "df_people_mentions = df_people_mentions[df_people_mentions['person'].isin(people_names)]\n",
        "\n",
        "# Group and pivot\n",
        "trend_people = (\n",
        "    df_people_mentions.groupby(['month', 'person'])\n",
        "    .size()\n",
        "    .reset_index(name='count')\n",
        "    .pivot(index='month', columns='person', values='count')\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj70-EOoiUfi"
      },
      "outputs": [],
      "source": [
        "trend_people.plot(marker='o', figsize=(14, 6))\n",
        "plt.title(\"Mentions of Top People in AI News Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Mentions\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Person\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZENoWiWLiWCg"
      },
      "source": [
        "#### location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCnqNcvOiW_y"
      },
      "outputs": [],
      "source": [
        "def normalize_location(loc):\n",
        "    loc = loc.strip().lower()\n",
        "    if loc in ['us', 'u.s.', 'u.s', 'usa', 'united states of america']:\n",
        "        return 'United States'\n",
        "    elif loc in ['uk', 'u.k.', 'england']:\n",
        "        return 'United Kingdom'\n",
        "    elif loc in ['china mainland']:\n",
        "        return 'China'\n",
        "    elif loc in ['eu', 'european union']:\n",
        "        return 'Europe'\n",
        "    else:\n",
        "        return loc.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9iI0ocPiYW6"
      },
      "outputs": [],
      "source": [
        "# Flatten and Normalize All Locations\n",
        "all_locations = [\n",
        "    normalize_location(loc)\n",
        "    for sublist in df_final['locations']\n",
        "    if isinstance(sublist, list)\n",
        "    for loc in sublist\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnQHbVk-icvr"
      },
      "outputs": [],
      "source": [
        "# Count Top 10 Locations\n",
        "top_location_counts = Counter(all_locations).most_common(10)\n",
        "location_names, location_counts = zip(*top_location_counts)\n",
        "top_locations = list(location_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkI7EdjsieFF"
      },
      "outputs": [],
      "source": [
        "# Bar Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(location_names[::-1], location_counts[::-1], color='mediumseagreen')\n",
        "plt.xlabel(\"Mention Count\")\n",
        "plt.title(\"Top 10 Locations Mentioned in AI News\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVtvF-9Yifa_"
      },
      "outputs": [],
      "source": [
        "# Prepare date column\n",
        "df_final['year_month'] = pd.to_datetime(df_final['date']).dt.to_period('M').astype(str)\n",
        "\n",
        "# Build time-based mention records\n",
        "records = []\n",
        "for i, row in df_final.iterrows():\n",
        "    if isinstance(row['locations'], list):\n",
        "        for loc in row['locations']:\n",
        "            norm_loc = normalize_location(loc)\n",
        "            if norm_loc in top_locations:\n",
        "                records.append((row['year_month'], norm_loc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLLLqSz2ihFx"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "df_location_mentions = pd.DataFrame(records, columns=['month', 'location'])\n",
        "\n",
        "# Group and pivot\n",
        "trend_locations = (\n",
        "    df_location_mentions.groupby(['month', 'location'])\n",
        "    .size()\n",
        "    .reset_index(name='count')\n",
        "    .pivot(index='month', columns='location', values='count')\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvwujQWQiioP"
      },
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "trend_locations.plot(marker='o', figsize=(14, 6))\n",
        "plt.title(\"Mentions of Top 10 Locations in AI News Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Mentions\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Location\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrB7a4NikNd"
      },
      "source": [
        "#### Technologies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehwj08dkil0K"
      },
      "outputs": [],
      "source": [
        "tech_aliases = {\n",
        "    # General concepts\n",
        "    \"large language model\": \"LLM\",\n",
        "    \"llm\": \"LLM\",\n",
        "    \"natural language processing\": \"NLP\",\n",
        "    \"nlp\": \"NLP\",\n",
        "    \"machine learning\": \"Machine Learning\",\n",
        "    \"deep learning\": \"Deep Learning\",\n",
        "    \"neural network\": \"Neural Network\",\n",
        "\n",
        "    # Specific technologies\n",
        "    \"chatgpt\": \"ChatGPT\",\n",
        "    \"gpt-3\": \"GPT-3\",\n",
        "    \"gpt-4\": \"GPT-4\",\n",
        "    \"gpt-4 turbo\": \"GPT-4\",\n",
        "    \"claude\": \"Claude\",\n",
        "    \"claude 2\": \"Claude\",\n",
        "    \"llama\": \"LLaMA\",\n",
        "    \"llama 2\": \"LLaMA\",\n",
        "    \"bard\": \"Bard\",\n",
        "    \"gemini\": \"Gemini\",\n",
        "    \"transformer\": \"Transformer\",\n",
        "    \"cuda\": \"CUDA\",\n",
        "    \"stable diffusion\": \"Stable Diffusion\",\n",
        "    \"dall-e\": \"DALL-E\",\n",
        "    \"midjourney\": \"Midjourney\",\n",
        "    \"autogpt\": \"AutoGPT\",\n",
        "    \"langchain\": \"LangChain\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h99zHqKEioX7"
      },
      "outputs": [],
      "source": [
        "def extract_and_map_technologies(text):\n",
        "    text_lower = text.lower()\n",
        "    found = set()\n",
        "    for key, unified in tech_aliases.items():\n",
        "        if key in text_lower:\n",
        "            found.add(unified)\n",
        "    return list(found)\n",
        "\n",
        "df_final['technologies'] = df_final['text'].apply(extract_and_map_technologies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Bd8KyFRip1s"
      },
      "outputs": [],
      "source": [
        "all_techs = [\n",
        "    tech for sublist in df_final['technologies']\n",
        "    if isinstance(sublist, list)\n",
        "    for tech in sublist\n",
        "]\n",
        "\n",
        "top_techs = [tech for tech, _ in Counter(all_techs).most_common(10)]\n",
        "tech_counts = Counter(all_techs).most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5FMap1pirpR"
      },
      "outputs": [],
      "source": [
        "# bar plot\n",
        "tech_names, tech_values = zip(*tech_counts)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tech_names[::-1], tech_values[::-1], color='slateblue')\n",
        "plt.title(\"Top 10 Mentioned AI Technologies\")\n",
        "plt.xlabel(\"Mention Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBg3Ax5zis6i"
      },
      "outputs": [],
      "source": [
        "df_final['year_month'] = pd.to_datetime(df_final['date']).dt.to_period('M').astype(str)\n",
        "\n",
        "tech_records = []\n",
        "for _, row in df_final.iterrows():\n",
        "    if isinstance(row['technologies'], list):\n",
        "        for tech in row['technologies']:\n",
        "            if tech in top_techs:\n",
        "                tech_records.append((row['year_month'], tech))\n",
        "\n",
        "df_tech_mentions = pd.DataFrame(tech_records, columns=['month', 'technology'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fscq_ItziupA"
      },
      "outputs": [],
      "source": [
        "# Pivot the count by month\n",
        "tech_trend = (\n",
        "    df_tech_mentions.groupby(['month', 'technology'])\n",
        "    .size()\n",
        "    .reset_index(name='count')\n",
        "    .pivot(index='month', columns='technology', values='count')\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMfkeR_BiwQH"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "tech_trend.plot(marker='o', figsize=(14, 6))\n",
        "plt.title(\"Technology Mentions Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Number of Mentions\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Technology\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg3r26U4izkn"
      },
      "source": [
        "### Topic-Level Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd4D6a-3ixgk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize VADER\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCkBx80wi1Ru"
      },
      "outputs": [],
      "source": [
        "def get_sentiment(text):\n",
        "    return sia.polarity_scores(text)['compound']\n",
        "\n",
        "# Compute sentiment per article\n",
        "df_final['sentiment'] = df_final['text'].apply(get_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U21p3eMji2zH"
      },
      "outputs": [],
      "source": [
        "topic_sentiment = df_final.groupby('topic')['sentiment'].mean().reset_index()\n",
        "topic_sentiment.columns = ['topic', 'avg_sentiment']\n",
        "topic_sentiment = topic_sentiment.sort_values(by='avg_sentiment', ascending=False)\n",
        "\n",
        "# Optional: Merge back to include topic keywords or industry\n",
        "df_topic_keywords = topic_model.get_topic_info()[['Topic', 'Name']]\n",
        "topic_sentiment = topic_sentiment.merge(df_topic_keywords, left_on='topic', right_on='Topic')\n",
        "topic_sentiment[['topic', 'Name', 'avg_sentiment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUj3SQeKi4Nu"
      },
      "outputs": [],
      "source": [
        "# Group by time + topic label\n",
        "df_final['year_month'] = df_final['date'].dt.to_period('M').astype(str)\n",
        "\n",
        "topic_sentiment_time = df_final.groupby(['year_month', 'topic_label'])['sentiment'].mean().reset_index()\n",
        "\n",
        "# Pivot for line plot\n",
        "pivot_topic_sent = topic_sentiment_time.pivot(index='year_month', columns='topic_label', values='sentiment').fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEbE27Imi5xe"
      },
      "outputs": [],
      "source": [
        "# Define label function\n",
        "def sentiment_label(score):\n",
        "    if score >= 0.5:\n",
        "        return 'Positive'\n",
        "    elif score <= 0.5 and score >=0.05:\n",
        "        return 'Slightly Positive'\n",
        "    elif score <= -0.5:\n",
        "        return 'Negative'\n",
        "    elif score >= -0.5 and score <=-0.05:\n",
        "        return 'Slightly Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply to your DataFrame\n",
        "df_final['sentiment_label'] = df_final['sentiment'].apply(sentiment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jma3Ukbci7Mo"
      },
      "outputs": [],
      "source": [
        "sentiment_counts = df_final['sentiment_label'].value_counts()\n",
        "\n",
        "# Plot overall sentiment distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='Set2')\n",
        "plt.title(\"Sentiment Distribution Across All Articles\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfAj7fUbi8ii"
      },
      "outputs": [],
      "source": [
        "df_final['year_month'] = pd.to_datetime(df_final['date']).dt.to_period('M').astype(str)\n",
        "# Calculate average sentiment per topic per month\n",
        "topic_sentiment_time = (\n",
        "    df_final.groupby(['year_month', 'topic_label'])['sentiment']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "pivot_topic_sentiment = topic_sentiment_time.pivot(\n",
        "    index='year_month',\n",
        "    columns='topic_label',\n",
        "    values='sentiment'\n",
        ").fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEQohNBFi99-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "pivot_topic_sentiment.plot(marker='o', figsize=(16, 6))\n",
        "plt.title(\"Topic-Level Sentiment Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Average Sentiment Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Topic\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI0Vh69bjBIm"
      },
      "source": [
        "### Entity-Level Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_WKzqOxi_RU"
      },
      "outputs": [],
      "source": [
        "# Build entity-level records\n",
        "records = []\n",
        "for i, row in df_final.iterrows():\n",
        "    if isinstance(row['organizations'], list):\n",
        "        for org in row['organizations']:\n",
        "            records.append((row['year_month'], org.strip(), row['sentiment']))\n",
        "\n",
        "df_entity_sent = pd.DataFrame(records, columns=['month', 'entity', 'sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkqaEC-BjDw0"
      },
      "outputs": [],
      "source": [
        "def normalize_entity(name):\n",
        "    name = name.lower()\n",
        "    name_map = {\n",
        "        'nvidia': 'NVIDIA',\n",
        "        'nvidias': 'NVIDIA',\n",
        "        'openai': 'OpenAI',\n",
        "        'microsoft': 'Microsoft',\n",
        "        'meta': 'Meta',\n",
        "        'google': 'Google',\n",
        "        'chatgpt': 'ChatGPT',\n",
        "        'amazon': 'Amazon',\n",
        "        'apple': 'Apple',\n",
        "        'gray media group': 'Gray Media Group',\n",
        "        'gpt': 'ChatGPT'\n",
        "    }\n",
        "    return name_map.get(name, name.title())\n",
        "\n",
        "df_entity_sent['entity'] = df_entity_sent['entity'].apply(normalize_entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSIW0mr_jFRd"
      },
      "outputs": [],
      "source": [
        "top_entities = [\n",
        "    ent for ent, _ in Counter(df_entity_sent['entity']).most_common(15)\n",
        "    if ent.lower() != 'ai'\n",
        "][:10]\n",
        "\n",
        "df_entity_sent_top = df_entity_sent[df_entity_sent['entity'].isin(top_entities)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e9x9YZPjHKR"
      },
      "outputs": [],
      "source": [
        "df_entity_sent_top['sentiment_label'] = df_entity_sent_top['sentiment'].apply(sentiment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbl70KTCjIZ6"
      },
      "outputs": [],
      "source": [
        "# Count sentiment labels\n",
        "sentiment_counts = (\n",
        "    df_entity_sent_top.groupby(['entity', 'sentiment_label'])\n",
        "    .size()\n",
        "    .reset_index(name='count')\n",
        ")\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(\n",
        "    data=sentiment_counts,\n",
        "    x='entity',\n",
        "    y='count',\n",
        "    hue='sentiment_label',\n",
        "    palette='Set2'\n",
        ")\n",
        "plt.title(\"Entity-Level Sentiment Distribution (Excluding 'AI')\")\n",
        "plt.xlabel(\"Entity\")\n",
        "plt.ylabel(\"Number of Mentions\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title=\"Sentiment\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQQA-Q_gjKZl"
      },
      "outputs": [],
      "source": [
        "# Average sentiment over time per entity\n",
        "sentiment_time = (\n",
        "    df_entity_sent_top.groupby(['month', 'entity'])['sentiment']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .pivot(index='month', columns='entity', values='sentiment')\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDBMYPvOjMby"
      },
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "sentiment_time.plot(marker='o', figsize=(16, 6))\n",
        "plt.title(\"Entity-Level Sentiment Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Average Sentiment Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Entity\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0ecNnsLjPnZ"
      },
      "source": [
        "### Visualization of sentiment analysis over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N8in4V2jN9q"
      },
      "outputs": [],
      "source": [
        "# Ensure date is datetime\n",
        "df_final['date'] = pd.to_datetime(df_final['date'])\n",
        "\n",
        "# Extract year-month\n",
        "df_final['year_month'] = df_final['date'].dt.to_period('M').astype(str)\n",
        "\n",
        "# Average sentiment per month\n",
        "sentiment_over_time = (\n",
        "    df_final.groupby('year_month')['sentiment']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnq5RdTAjRaA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(sentiment_over_time['year_month'], sentiment_over_time['sentiment'], marker='o')\n",
        "plt.title('Average Sentiment Over Time')\n",
        "plt.xlabel('Year-Month')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai_gpu_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
